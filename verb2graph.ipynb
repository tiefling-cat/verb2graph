{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re, scipy\n",
    "import numpy as np\n",
    "from os import mkdir\n",
    "import os\n",
    "from time import process_time\n",
    "\n",
    "import networkx as nx\n",
    "import community\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    " \n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "rc('font', **font)\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Model = namedtuple('Model', ['filename', 'threshold', 'topk', 'binary', 'verbs'])\n",
    "\n",
    "def make_combined_graph(model_designation_list):\n",
    "    model_list, verb_list_combined = [], []\n",
    "    for model_designation in model_designation_list:\n",
    "        print('Processing model {} with threshold {}.'.format(*model_designation))\n",
    "        model_bin = load_model(model_designation[0])\n",
    "        verb_list = get_verbs(model_bin)\n",
    "        verb_list_combined.extend(verb_list)\n",
    "        model_list.append(Model(model_designation[0], model_designation[1], model_bin, set(verb_list)))\n",
    "        print()\n",
    "    verb_list_combined = list(set(verb_list_combined))\n",
    "    print('Combined verb list volume {}.\\n'.format(len(verb_list_combined)))\n",
    "\n",
    "    print('Creating new graph...    ', end = '')\n",
    "    G = nx.Graph()\n",
    "    print('Done!\\nAdding nodes...          ', end = '')\n",
    "    G.add_nodes_from(verb_list_combined)\n",
    "    print('Done!\\nAdding edges...          ', end = '')\n",
    "    \n",
    "    for i, verb1 in enumerate(verb_list_combined):\n",
    "        for verb2 in verb_list_combined[i+1:]:\n",
    "            for model in model_list:\n",
    "                if verb1 in model.verbs and verb2 in model.verbs:\n",
    "                    sim = model.binary.similarity(verb1, verb2)\n",
    "                    if sim > model.threshold:\n",
    "                        G.add_edge(verb1, verb2)\n",
    "                        \n",
    "    print('Done!\\n')\n",
    "    print(nx.info(G))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_model(fname):\n",
    "    model = Word2Vec.load_word2vec_format(fname, binary=True)\n",
    "    print('Model vocabulary volume', len(model.vocab))\n",
    "    return model\n",
    "\n",
    "def get_mverbs(model):\n",
    "    model_verb_set = set()\n",
    "    for word in model.vocab:\n",
    "        match = re.match('.*_V', word)\n",
    "        if match:\n",
    "            model_verb_set.add(word)\n",
    "    print('Model verb list volume', len(model_verb_set))\n",
    "    return model_verb_set\n",
    "\n",
    "def get_fverbs():\n",
    "    freq_verb_set = set()\n",
    "    with open('aux/all_verbs.txt', 'r', encoding='utf-8') as ifile:\n",
    "        for line in ifile:\n",
    "            parts = line.strip('\\n').split('\\t')\n",
    "            freq_verb_set.add(parts[0] + '_V')\n",
    "    print('Frequency dictionary volume', len(freq_verb_set))\n",
    "    return freq_verb_set\n",
    "\n",
    "def get_verbs(model):\n",
    "    model_verb_set = get_mverbs(model)\n",
    "    freq_verb_set = get_fverbs()\n",
    "    verb_list = list(model_verb_set & freq_verb_set)\n",
    "    print('Intersected list volume', len(verb_list))\n",
    "    return verb_list\n",
    "\n",
    "def make_graph(model, verb_list, threshold, name=''):\n",
    "    G = nx.Graph(threshold = threshold)\n",
    "    print(\"Created graph\")\n",
    "    G.add_nodes_from(verb_list)\n",
    "    print(\"Added nodes\")\n",
    "    for i, verb1 in enumerate(verb_list):\n",
    "        for verb2 in verb_list[i+1:]:\n",
    "            sim = model.similarity(verb1, verb2)\n",
    "            if sim > threshold:\n",
    "                G.add_edge(verb1, verb2, weight=sim)\n",
    "    print(nx.info(G))\n",
    "    return G\n",
    "\n",
    "def make_graph_topK(model, verb_list, topK=10, name=''):\n",
    "\n",
    "    print('Creating new graph...    ', end = '')\n",
    "    G = nx.Graph(topK = topK)\n",
    "    print('Done!\\nAdding nodes...          ', end = '')\n",
    "    G.add_nodes_from(verb_list)\n",
    "    print('Done!\\nCalculating edges...          ', end = '')\n",
    "    btime = process_time()\n",
    "    edge_dict = {}\n",
    "    for verb in verb_list:\n",
    "        sim_words = model.most_similar(positive=[verb], topn=topK)\n",
    "        \n",
    "        #sim_verbs = {sim_word:score for (sim_word, score) in sim_words if sim_word.endswith('_V')}\n",
    "        #filtered_sim_verbs = list(set(sim_verbs.keys()) & verb_set)\n",
    "        #filtered_sim_verbs.sort(key=sim_verbs.get, reverse=True)\n",
    "        \n",
    "        #edge_dict.update({sim_word[0]:verb for sim_word in sim_words if sim_word[0].endswith('_V')})\n",
    "        \n",
    "        edge_dict.update({sim_word[0]:verb for sim_word in sim_words})\n",
    "    print(\"Done in {}\".format(process_time() - btime))\n",
    "    \n",
    "\n",
    "    print('Filtering edges...          ', end = '')\n",
    "    btime = process_time()\n",
    "    filtered = set(edge_dict.keys()) & set(verb_list)\n",
    "    print(\"Done in {}\".format(process_time() - btime))\n",
    "\n",
    "    print('Adding edges...          ', end = '')\n",
    "    btime = process_time()\n",
    "    G.add_edges_from([(edge_dict[word], word) for word in filtered])\n",
    "    print(\"Done in {}\".format(process_time() - btime))\n",
    "\n",
    "    print(nx.info(G))\n",
    "    return G\n",
    "\n",
    "def plot_subs(G, dirname):\n",
    "    mkdir(dirname)\n",
    "    plt.figure(figsize=(20,10), dpi=80)\n",
    "    plt.axis('off')\n",
    "    sub_gen = nx.connected_component_subgraphs(G)\n",
    "    i = 0\n",
    "    while True:\n",
    "        sub = next(sub_gen)\n",
    "        #print(re.sub('\\n', ' ', nx.info(sub)))\n",
    "        plt.clf()\n",
    "        nx.draw_networkx(sub, with_labels=True, node_size=1000, \n",
    "                         font_size=12, node_shape='o', alpha=0.8, node_color='green')\n",
    "        plt.savefig('{}/{}.png'.format(dirname, i))    \n",
    "        i += 1\n",
    "        \n",
    "def draw(G):\n",
    "    plt.figure(figsize=(20,20), dpi=80)\n",
    "    plt.axis('off')\n",
    "    nx.draw_networkx(G, with_labels=True, node_size=12000, font_size=18, \n",
    "                     node_shape='o', alpha=0.8, node_color='yellow', font_family='Verdana')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_good(G, filename=None):\n",
    "    plt.figure(figsize=(30,30), dpi=80)\n",
    "    plt.axis('off')\n",
    "    nx.draw_spring(G, with_labels=True, node_size=2000, font_size=20, font_family='Verdana')\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "    \n",
    "def draw_colored(G, func, cmap_name=None, colors=None):\n",
    "    plt.figure(figsize=(30,30), dpi=80)\n",
    "    plt.axis('off')\n",
    "    if cmap_name is not None and colors is not None:\n",
    "        func(G, with_labels=True, cmap = plt.get_cmap(cmap_name), node_size=2000, \n",
    "                font_size=20, node_color=colors, font_family='Verdana')\n",
    "    else:\n",
    "        func(G, with_labels=True, node_size=2000, font_size=20, font_family='Verdana')\n",
    "    \n",
    "def draw_colored_small(G, func, cmap_name=None, colors=None):\n",
    "    plt.figure(figsize=(20,20), dpi=80)\n",
    "    plt.axis('off')\n",
    "    if cmap_name is not None and colors is not None:\n",
    "        func(G, cmap = plt.get_cmap(cmap_name), node_size=50, node_color=colors, font_family='Verdana')\n",
    "    else:\n",
    "        func(G, node_size=50, font_family='Verdana')\n",
    "        \n",
    "def varinfo(G):\n",
    "    print('Density:', nx.density(G))\n",
    "    print()\n",
    "    #print('Center:', nx.center(I))\n",
    "    #print('Periphery:', nx.periphery(I))\n",
    "    #print()\n",
    "    print('Diameter =', nx.diameter(G))\n",
    "    print('Avg shortest path =', nx.average_shortest_path_length(G))\n",
    "    print()\n",
    "    print('Clustering')\n",
    "    print(sum(nx.triangles(G).values())/3)\n",
    "    print(nx.average_clustering(G))\n",
    "    print(nx.transitivity(G))\n",
    "    \n",
    "def component_hist(components):\n",
    "    lens = [nx.number_of_nodes(C) for C in components]\n",
    "    gcounter = Counter(lens)\n",
    "    print(sorted(gcounter.items(), reverse=True, key = itemgetter(0)))\n",
    "    hist = sorted(gcounter.items(), reverse=True, key = itemgetter(0))\n",
    "    d = [bar[1] for bar in hist[1:]]\n",
    "    c = [bar[0] for bar in hist[1:]]\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.bar(c,d,align='center')\n",
    "    #plt.plot(d,'.', ms =10)\n",
    "    plt.xticks(c)\n",
    "    #plt.yscale('log')\n",
    "    #plt.xscale('log')\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(\"бины\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('models/ruscorpora.model.bin')\n",
    "verb_list = get_verbs(model)\n",
    "G = make_graph_topK(model, verb_list, topK=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate combined models graph\n",
    "model_designation_list = [('web.model.bin', 0.6), ('ruscorpora.model.bin', 0.7)]\n",
    "G = make_combined_graph(model_designation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate connected components\n",
    "sub_gen = nx.connected_component_subgraphs(G)\n",
    "components = []\n",
    "for I in sub_gen:\n",
    "    components.append(I)\n",
    "components.sort(key=nx.number_of_nodes, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# draw histogram of component sizes\n",
    "component_hist(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output components big enough to be interesting\n",
    "for C in components[1:]:\n",
    "    if nx.number_of_nodes(C) > 10:\n",
    "        #print(nx.info(C))\n",
    "        draw_good(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('clusters.csv', 'w', encoding='utf-8') as ofile:\n",
    "    for i, I in enumerate(components):\n",
    "        #print(str(len(I.nodes())) + ', ' + ', '.join(I.nodes()))\n",
    "        ofile.write(', '.join([str(i+1), str(len(I.nodes()))] + I.nodes()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# draw the whole graph\n",
    "plt.figure(figsize=(20,20), dpi=80)\n",
    "plt.axis('off')\n",
    "nx.draw(G, node_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = components[0]\n",
    "print(nx.info(I))\n",
    "varinfo(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20), dpi=80)\n",
    "plt.axis('off')\n",
    "nx.draw(I, node_size=50)\n",
    "draw_good(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "varinfo(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degrees = np.asarray(list(nx.degree(I).values()))\n",
    "k_mean = np.mean(degrees)\n",
    "k_square_mean = np.mean(degrees * degrees)\n",
    "random_trans = (k_square_mean - k_mean) * (k_square_mean - k_mean) / (k_mean * k_mean * k_mean) / degrees.shape[0]\n",
    "print(random_trans)\n",
    "print(nx.transitivity(I) / random_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sorted(nx.degree(I).items(), reverse=True, key = itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = nx.degree_histogram(I)\n",
    "c = range(0,len(d),1)\n",
    "plt.figure(figsize=(25,15))\n",
    "plt.bar(c,d,align='center')\n",
    "#plt.plot(d,'.', ms =10)\n",
    "plt.xticks(c)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.grid(True,which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(I)\n",
    "print(A.shape)\n",
    "\n",
    "plt.spy(A, precision=0, marker='.', markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SD=pdist(A.toarray(),'cosine')\n",
    "M = 1-squareform(SD)\n",
    "plt.imshow(M,cmap='winter',interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = hierarchy.average(SD)\n",
    "hh=hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_circ(G):\n",
    "    plt.figure(figsize=(20,10), dpi=80)\n",
    "    plt.axis('off')\n",
    "    nx.draw_circular(G, with_labels=True, node_size=500, font_size=16, node_color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(nx.graph_clique_number(I))\n",
    "print(nx.graph_number_of_cliques(I))\n",
    "cliques = list(nx.find_cliques(I)) \n",
    "print(cliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clique in sorted(cliques, key=len, reverse=True):\n",
    "    if len(clique) > 2:\n",
    "        iclique = I.subgraph(clique)\n",
    "        draw_circ(iclique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cores=nx.core_number(I)\n",
    "#print(cores)\n",
    "sorted_cores = sorted(cores.items(), key=itemgetter(1))\n",
    "#print(sorted_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_core = sorted_cores[-1][1]\n",
    "for core in range(max_core, 0, -1):\n",
    "    core_nodes = [coreitem[0] for coreitem in sorted_cores if coreitem[1] >= core]\n",
    "    CG = I.subgraph(core_nodes)\n",
    "    draw_colored_small(CG, nx.draw_circular)\n",
    "    draw_colored(CG, nx.draw_circular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = [cores[node] for node in I.nodes()]\n",
    "#draw_colored(I, 'spring', colors)\n",
    "draw_colored_small(I, nx.draw, 'autumn', colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_communities(G):\n",
    "    partition = community.best_partition(G)\n",
    "    return flatten_partition(partition)\n",
    "\n",
    "def flatten_partition(partition):\n",
    "    communities = {}\n",
    "    for key in partition:\n",
    "        comm = partition[key]\n",
    "        communities[comm] = communities.get(comm, []) + [key]\n",
    "    communities = sorted(communities.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    return communities    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dendo = community.generate_dendogram(I)\n",
    "comms = community.partition_at_level(dendo, 0)\n",
    "colors = [comms[node] for node in I.nodes()]\n",
    "draw_colored(I, nx.draw_spring, 'Accent', colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dendo = community.generate_dendogram(components[0])\n",
    "comms = flatten_partition(community.partition_at_level(dendo, 0))\n",
    "\n",
    "for comm in comms:\n",
    "    if len(comm[1]) > 10:\n",
    "        ComGr = components[0].subgraph(comm[1])\n",
    "        comdendo = community.generate_dendogram(ComGr)\n",
    "        compart = community.partition_at_level(comdendo, 0)\n",
    "        \n",
    "        colors = [compart[node] for node in ComGr.nodes()]\n",
    "        draw_colored(ComGr, nx.draw, 'Accent', colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_cent(G, cent_dict, lbls=False):\n",
    "    cents = [cent_dict[x] for x in G.nodes()]\n",
    "    max_cent = max(cents)\n",
    "    sizes = [cent / max_cent * 10000 for cent in cents]\n",
    "    colors = [float(cent_dict[x]) for x in G.nodes()]\n",
    "    plt.figure(figsize=(20,20), dpi=80)\n",
    "    plt.axis('off')\n",
    "    nx.draw(G, node_size=sizes, with_labels=lbls, node_color=colors, cmap = plt.cm.winter, font_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cent_func in [\n",
    "    nx.degree_centrality, \n",
    "    nx.betweennes_centrality, \n",
    "    nx.closeness_centrality, \n",
    "    nx.eigenvector_centrality]:\n",
    "\n",
    "    cent = cent_func(I)\n",
    "    print(sorted(cent.items(),reverse=True,key = itemgetter(1))[:10])\n",
    "    draw_cent(I, cent, lbls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dcent = nx.degree_centrality(I)\n",
    "print(sorted(dcent.items(),reverse=True,key = itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_cent(I, dcent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcent=nx.betweenness_centrality(I)\n",
    "print(sorted(bcent.items(),reverse=True,key = itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_cent(I, bcent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccent=nx.closeness_centrality(I)\n",
    "print(sorted(ccent.items(),reverse=True,key = itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_cent(I, ccent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecent=nx.eigenvector_centrality_numpy(I)\n",
    "print(sorted(ecent.items(),reverse=True,key = itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_cent(I, ecent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
